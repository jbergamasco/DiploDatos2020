{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"4- Aprendizaje No Supervisado - Precios Claros.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"KN-QlMNYyc0G","colab_type":"text"},"source":["<center>\n","<h4>Diplomatura en CDAAyA 2020 - FaMAF - UNC</h4>\n","<h1>¿Caro o Barato? Análisis de Precios de Almacen en un Contexto Inflacionario</h1>\n","<h3>Aprendizaje Automático No Supervisado</h3>\n","</center>\n","</left>\n","<h4>Sofía Luján y Julieta Bergamasco</h4>\n","</left>"]},{"cell_type":"markdown","metadata":{"id":"idfFt1rKyc0G","colab_type":"text"},"source":["### Introducción\n","\n","En la siguiente notebook se presentará la consigna a seguir para el cuarto y último práctico del proyecto, correspondiente a la materia Aprendizaje Automático No Supervisado. El objetivo consiste en aplicar distintas técnicas de análisis exploratorio de datos (EDA) al dataset, de modo de encontrar patrones sistematizables. A los fines de este práctico, *nos enfocaremos en clasificar los productos y la búsqueda de valores atípicos (outliers).*\n","\n","Luego, una vez aplicadas las técnicas de aprendizaje no supervisado y del cálculo de las métricas pertinentes, podremos recurrir a las etiquetas de clases con el fin de contrastar los resultados obtenidos.\n","\n","Para ello, comenzaremos con las importaciones pertinentes."]},{"cell_type":"markdown","metadata":{"id":"9D_kS3l_yc0H","colab_type":"text"},"source":["### Importaciones"]},{"cell_type":"code","metadata":{"id":"KumMUoDAyc0H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1600815338778,"user_tz":180,"elapsed":2330,"user":{"displayName":"sofia lujan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRjGY1pGqEbZ6NzzBty0QMgutVKtWpvUr5f7ch8Q=s64","userId":"04644358706352499859"}},"outputId":"560ad751-4a31-4425-b7c0-ce7d50788c4e"},"source":["# Importación de las librerías necesarias\n","import numpy as np\n","import pandas as pd\n","# Puede que nos sirvan también\n","import matplotlib as mpl\n","mpl.get_cachedir()\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","# import sklearn as skl\n","\n","from sklearn import preprocessing\n","from sklearn.utils import shuffle\n","from sklearn.decomposition.pca import PCA\n","from sklearn.decomposition import FactorAnalysis\n","from sklearn.cluster import KMeans\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","from sklearn.model_selection import train_test_split\n","\n","random_state = 0\n","np.random.seed(0)  # Para mayor determinismo"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.decomposition.pca module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8iBd6vHOyc0K","colab_type":"code","colab":{}},"source":["pd.set_option('display.max_columns', 150)\n","pd.set_option('display.max_rows', 150)\n","pd.set_option('max_colwidth', 151)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EGUx_xBtyc0M","colab_type":"text"},"source":["## Consigna para Aprendizaje Automático No Supervisado"]},{"cell_type":"markdown","metadata":{"id":"liXyK5Uyyc0N","colab_type":"text"},"source":["### I. Preprocesamiento\n","\n","A los fines de realizar este práctico, se utilizará el dataset crudo. El preprocesamiento será similar al aplicado en los prácticos anteriores.\n","\n","#### 1. Obtención del Dataset\n","\n","Cargar el conjunto de datos original. \n","\n","#### 2. Aplicar Script de Curación\n","\n","Inicialmente, con el objetivo de preparar los datos que alimentarán los modelos de aprendizaje automático (ML) propuestos, deberán aplicar el script de curación obtenido en el práctico anterior.\n","\n","#### 3. Creación de Nuevos Atributos\n","\n","En esta etapa, pueden adicionar atributos calculados a partir de los datos preexistentes, que crean que son pertinentes a priori o que hayan encontrado interesantes por tener mayor correlación con `precio relativo`. Por ejemplo, el precio relativo del período anterior.\n","\n","#### 4. Normalización de Atributos\n","\n","Es posible que sea necesario normalizar las features de nuestro dataset, dado que los algoritmos de clasificación no supervisada lo requieren. Aplicar al dataset la normalización de atributos que consideren adecuada.\n","\n","#### 5. Mezca Aleatória y División en Train/Test\n","\n","Finalmente, es recomendable que mezclen los datos aleatoriamente, dado que la inicialización influye en los resultados del modelo que se propone que implementen.\n","\n","Respecto a la división en Train/Test, dado que se trata de un algoritmo de aprendizaje automático no supervisado, pueden omitir esta división, ya que estamos buscando patrones ocultos en los datos que reflejen las causas latentes.\n","\n","---\n","\n","A modo de ayuda, **en esta notebook encontrarán una especie de template** que sigue los pasos propuestos y que deberán ir completando.\n","\n","Recuerden que la ciencia de datos es un **proceso circular, continuo y no lineal**. Es decir, si los datos requieren de mayor procesamiento para satisfacer las necesidades de algoritmos de ML (cualesquiera de ellos), vamos a volver a la etapa inicial para, por ejemplo, crear nuevas features, tomar decisiones diferentes sobre valores faltantes o valores atípicos (outliers), descartar features, entre otras."]},{"cell_type":"markdown","metadata":{"id":"-IPY6rQFyc0N","colab_type":"text"},"source":["### II. Aplicación de Modelos de Aprendizaje Automático No Supervisado\n","\n","Una vez finalizada la etapa de preprocesamiento, se propone implementar, por un lado, una técnica de reducción de dimensionalidad para representar los datos y, por el otro, dos técnicas de clusterización.\n","\n","#### 1. Descomposición de Variables: Principal Component Analysis\n","\n","Si bien la mayoría de nuestros atributos se tratan de variables binarias y PCA no es tan apropiado para este tipo de datasets, puede aplicarse esta técnica y ver que resulta.\n","A partir del análisis y la visualización de los datasets transformados por PCA, obtener conclusiones.\n","\n","Adicionalmente, existe una técnica llamada Factor Analysis que puede ser más apropiada para este caso. Aplicarla y obtener conclusiones. Comparar con los resultados obtenidos previamente.\n","\n","#### 2. K-Means Clustering\n","Aplicar K-Means tanto al dataset original como al dataset transformado a partir de cualquiera de las técnicas anteriores.\n","\n","Explorar distintas soluciones de clustering con diferentes parámetros, como iteraciones, número de clusters o métricas de distancia, y compararlas. Finalmente, para el modelo seleccionado:\n","\n","- Calcular las métricas pertinentes sobre los clusters resultantes.\n","- Aplicando el método de Elbow, ¿cuál sería la cantidad óptima de clusters?\n","- Agregar al dataset original el cluster resultante de los modelos.\n","- Graficar diferentes variables de interés por cluster y compararlos.\n","- Tomar ejemplos aleatorios y pensar por qué están en un cluster y no en otro.\n","- Calcular los centroides y tratar de mostrar qué tiene cada cluster cerca de su centroide. Obtener conclusiones.\n","- Graficar la silhouette utilizando distancia Manhattan. [Definición](https://en.wikipedia.org/wiki/Silhouette_(clustering)#:~:text=The%20silhouette%20value%20is%20a,poorly%20matched%20to%20neighboring%20clusters) y \n","[Doc+Ejemplo](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)\n","\n","#### 3. HDBScan en cada cluster para detectar anomalías.\n","\n","[Lib and Doc](https://hdbscan.readthedocs.io/en/latest/) y\n","[Más Doc](https://towardsdatascience.com/understanding-hdbscan-and-density-based-clustering-121dbee1320e)\n","\n","Este algoritmo es de clusterización apropiado para detectar anomalias (outliers). El resultado deberían ser un set de productos caros o baratos dentro de cada cluster identificado en la etapa anterior."]},{"cell_type":"markdown","metadata":{"id":"7O4aUS9hBW6V","colab_type":"text"},"source":["---\n","### III. Opcional - Tareas Adicionales\n","\n","1. Incluir clusters como una nueva feature en el modelo seleccionado en el práctico de aprendizaje supervisado. A partir de esto, obtener conclusiones de acuerdo al error de predicción. **Productos caros**: aquellos con error de predicción positivo alto. **Productos baratos**: aquellos con error de predicción negativo alto. ¿Tiene sentido?\n","\n","2. Al obtener la predicción del precio, se llega al **precio relativo estimado**. Hacer la transformación inversa para identificar cuál debería ser el precio nominal de ese producto particular. ¿Qué dato necesitamos conocer si estamos prediciendo los precios de hoy?\n","\n","3. Probar los modelos con los nuevos datos disponibilizados.\n"]},{"cell_type":"markdown","metadata":{"id":"eJ041aJtyc0N","colab_type":"text"},"source":["### Entregables\n","\n","El entregable de este práctico consiste en **esta misma Notebook**, pero con el preprocesamiento aplicado y las técnicas implementadas, agregando las explicaciones que crean pertinentes y las decisiones tomadas, en caso de corresponder.\n","\n","Sintetizar las conclusiones en un archivo de texto, como lo vienen haciendo con los anteriores prácticos.\n","\n","**Fecha de Entrega: 13/10**"]},{"cell_type":"markdown","metadata":{"id":"riyukmKuyc0O","colab_type":"text"},"source":["# Resolución"]},{"cell_type":"markdown","metadata":{"id":"ANOb6gXKyc0O","colab_type":"text"},"source":["## I. Preprocesamiento\n","\n","### 1. Carga de Datos"]},{"cell_type":"markdown","metadata":{"id":"BQPjJJeIyc0O","colab_type":"text"},"source":["Para comenzar, importamos los datos que vamos a utilizar:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"dYHgew-pyc0P","colab_type":"code","colab":{}},"source":["# Cargamos el dataset original en una variable\n","precios_20200412_20200413 = pd.read_csv('https://raw.githubusercontent.com/solujan/mentoria_2020/master/raw_dataset/precios_20200412_20200413.csv')\n","precios_20200419_20200419 = pd.read_csv('https://raw.githubusercontent.com/solujan/mentoria_2020/master/raw_dataset/precios_20200419_20200419.csv')\n","precios_20200426_20200426 = pd.read_csv('https://raw.githubusercontent.com/solujan/mentoria_2020/master/raw_dataset/precios_20200426_20200426.csv')\n","precios_20200502_20200503 = pd.read_csv('https://raw.githubusercontent.com/solujan/mentoria_2020/master/raw_dataset/precios_20200502_20200503.csv')\n","precios_20200518_20200518 = pd.read_csv('https://raw.githubusercontent.com/solujan/mentoria_2020/master/raw_dataset/precios_20200518_20200518.csv')\n","\n","productos = pd.read_csv('https://raw.githubusercontent.com/solujan/mentoria_2020/master/raw_dataset/productos.csv')\n","sucursales = pd.read_csv('https://raw.githubusercontent.com/solujan/mentoria_2020/master/raw_dataset/sucursales.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lbcfUpdCahP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1600817864180,"user_tz":180,"elapsed":732,"user":{"displayName":"sofia lujan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRjGY1pGqEbZ6NzzBty0QMgutVKtWpvUr5f7ch8Q=s64","userId":"04644358706352499859"}},"outputId":"17e8b956-3666-4be9-ed98-a7b9d3b9b379"},"source":["productos.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>marca</th>\n","      <th>nombre</th>\n","      <th>presentacion</th>\n","      <th>categoria1</th>\n","      <th>categoria2</th>\n","      <th>categoria3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000000001663</td>\n","      <td>LA ANÓNIMA</td>\n","      <td>Radicheta Atada La Anonima 1 Un</td>\n","      <td>1.0 un</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0000000002288</td>\n","      <td>LA ANÓNIMA</td>\n","      <td>Perejil Atado La Anonima 1 Un</td>\n","      <td>1.0 un</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0000000205870</td>\n","      <td>SIN MARCA</td>\n","      <td>Ojo de Bife 1 Kg</td>\n","      <td>1.0 kg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0000000205894</td>\n","      <td>SIN MARCA</td>\n","      <td>Milanesa de Peceto Novillito 1 Kg</td>\n","      <td>1.0 kg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0000000205955</td>\n","      <td>SIN MARCA</td>\n","      <td>Chiquizuela Novillito 1 Kg</td>\n","      <td>1.0 kg</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              id       marca                             nombre presentacion  \\\n","0  0000000001663  LA ANÓNIMA    Radicheta Atada La Anonima 1 Un       1.0 un   \n","1  0000000002288  LA ANÓNIMA      Perejil Atado La Anonima 1 Un       1.0 un   \n","2  0000000205870   SIN MARCA                   Ojo de Bife 1 Kg       1.0 kg   \n","3  0000000205894   SIN MARCA  Milanesa de Peceto Novillito 1 Kg       1.0 kg   \n","4  0000000205955   SIN MARCA         Chiquizuela Novillito 1 Kg       1.0 kg   \n","\n","  categoria1 categoria2 categoria3  \n","0        NaN        NaN        NaN  \n","1        NaN        NaN        NaN  \n","2        NaN        NaN        NaN  \n","3        NaN        NaN        NaN  \n","4        NaN        NaN        NaN  "]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"VQ_ZNbVyLmai","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1600817887045,"user_tz":180,"elapsed":498,"user":{"displayName":"sofia lujan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRjGY1pGqEbZ6NzzBty0QMgutVKtWpvUr5f7ch8Q=s64","userId":"04644358706352499859"}},"outputId":"1fb1c366-19e8-4679-d299-076eadc6156b"},"source":["precios_20200518_20200518.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precio</th>\n","      <th>producto_id</th>\n","      <th>sucursal_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>29.90</td>\n","      <td>0000000002288</td>\n","      <td>2-1-009</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>32.90</td>\n","      <td>0000000002288</td>\n","      <td>2-1-037</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36.90</td>\n","      <td>0000000002288</td>\n","      <td>2-1-090</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>39.90</td>\n","      <td>0000000002288</td>\n","      <td>2-3-247</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>499.99</td>\n","      <td>0000000205870</td>\n","      <td>9-1-430</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   precio    producto_id sucursal_id\n","0   29.90  0000000002288     2-1-009\n","1   32.90  0000000002288     2-1-037\n","2   36.90  0000000002288     2-1-090\n","3   39.90  0000000002288     2-3-247\n","4  499.99  0000000205870     9-1-430"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"WTitg7qEyc0X","colab_type":"text"},"source":["<div class=\"alert alert-block alert-info\">\n","El dataset ya está **listo para trabajar!**\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"FMsCcKA3yc0X","colab_type":"text"},"source":["### 2. Aplicar Script de Curación"]},{"cell_type":"markdown","metadata":{"id":"_8F8pyseyc0X","colab_type":"text"},"source":["El siguiente paso implica aplicar el script que resultó del práctico anterior. También pueden adicionar campos calculados en base a otros atributos, según lo consideren pertinente."]},{"cell_type":"code","metadata":{"id":"u8ANmWIsyc0Y","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2rcC2wzhyc0c","colab_type":"text"},"source":["### 3. Creación de Nuevos Atributos"]},{"cell_type":"markdown","metadata":{"id":"vrCJ6SG-yc0d","colab_type":"text"},"source":["Decisiones al respecto:"]},{"cell_type":"code","metadata":{"id":"WExctaV8yc0d","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-WTg7BBkyc0i","colab_type":"text"},"source":["### 4. Normalización de Atributos"]},{"cell_type":"markdown","metadata":{"id":"smywX288yc0j","colab_type":"text"},"source":["Aplicar al dataset la normalización de atributos que consideren adecuada."]},{"cell_type":"code","metadata":{"id":"Y6CyHnUkyc0j","colab_type":"code","colab":{}},"source":["# Pueden utilizar los siguientes métodos, por ejemplo:\n","\n","min_max_scaler = preprocessing.MinMaxScaler()\n","standard_scaler = preprocessing.StandardScaler()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vRiqHhEHyc0l","colab_type":"text"},"source":["### 5. Mezca Aleatória y División en Train/Test\n","\n","Mezclar los datos aleatoriamente. Luego, si les parece necesario, dividir en Train/Test el dataset."]},{"cell_type":"code","metadata":{"id":"L9hGvZr-yc0l","colab_type":"code","colab":{}},"source":["# Para mezclar aleatoriamente el dataset, utilizar el siguiente módulo:\n","\n","_ds_shuff = shuffle(_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"izzqx0ykyc0o","colab_type":"text"},"source":["## II. Aplicación de Modelos de Aprendizaje Automático No Supervisado"]},{"cell_type":"markdown","metadata":{"id":"r9gAOtRmyc0o","colab_type":"text"},"source":["Utilizando los datos obtenidos, se aplicarán técnicas de reducción de dimensionalidad y el modelo K-Means de Clustering."]},{"cell_type":"markdown","metadata":{"id":"xgPnEygLyc0o","colab_type":"text"},"source":["### 1. Descomposivión de Variables: Principal Component Analysis"]},{"cell_type":"markdown","metadata":{"id":"x_Ub1BM1yc0p","colab_type":"text"},"source":["A continuación se aplicará la técnica de descomposición por Análisis de Componente Principal (PCA)."]},{"cell_type":"code","metadata":{"id":"gaY6gBZZyc0p","colab_type":"code","colab":{}},"source":["# Utilizar diferentes valores para el parámetro n_components\n","\n","pca = PCA()\n","pca_ind = pca.fit_transform(_ds)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hj3LFUnnyc0t","colab_type":"code","colab":{}},"source":["fa = FactorAnalysis(n_components=7, random_state=0)\n","fa_ds = fa.fit_transform(_ds)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CwVGVgVDyc0v","colab_type":"text"},"source":["Si se animan, pueden usar una red neuronal como encoder para la reducción de dimensionalidad.\n","\n","***Hint: *** [En el siguiente link](https://medium.com/intuitive-deep-learning/autoencoders-neural-networks-for-unsupervised-learning-83af5f092f0b)"]},{"cell_type":"markdown","metadata":{"id":"EZSoBqgayc0v","colab_type":"text"},"source":["### 2.  K-Means Clustering"]},{"cell_type":"markdown","metadata":{"id":"e8P9BqXyyc0v","colab_type":"text"},"source":["A continuación se aplicará K-Means para clasificar en clusters nuestros datasets."]},{"cell_type":"code","metadata":{"id":"thQDpC_ryc0w","colab_type":"code","colab":{}},"source":["num_clusters = 5\n","km = KMeans(n_clusters=num_clusters)\n","km.fit(_ds)\n","\n","clusters = km.labels_.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1NF_z40Kyc0y","colab_type":"code","colab":{}},"source":["print (clusters)\n","\n","# Recuento del número de elementos en cada cluster\n","for i in range(num_clusters):\n","    print ('El cluster %i tiene %i elementos' % (i, clusters.count(i)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFOfKgPQyc00","colab_type":"code","colab":{}},"source":["# Agrupar por clusters y clases los datasets, utilizando .count()\n","_ds['cluster'] = clusters\n","_ds['cluster'].value_counts()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JL90DI8Oyc01","colab_type":"code","colab":{}},"source":["# Calcular estadísticos relevantes para variables clave del dataset, diferenciados por cada cluster\n","# Pueden usar .describe()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Trz_krvLyc03","colab_type":"code","colab":{}},"source":["# Para encontrar los centroides y analizarlos pueden utilizar lo siguiente:\n","centroids = km.cluster_centers_   # centroids = km.centroids\n","order_centroids = centroids.argsort()[:, ::-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVY3Qqqgyc05","colab_type":"code","colab":{}},"source":["# Aplicar método de Elbow para identificar el número de clusters óptimo\n","n = \n","sum_sq_dist = []\n","list_k = list(range(1, n))\n","\n","for k in list_k:\n","    km = KMeans(n_clusters=k)\n","    km.fit(_ds_individual)\n","    sum_sq_dist.append(km.inertia_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLQtSRAkyc07","colab_type":"code","colab":{}},"source":["# Calcular la métrica de la silueta. Pueden usar los módulos silhouette_samples y silhouette_score\n","\n","silhouette_vals = silhouette_samples(_ds, clusters)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4wklDY4Ryc09","colab_type":"text"},"source":["Graficar diferentes variables de interés por cluster y compararlos."]},{"cell_type":"code","metadata":{"id":"lSNEMRWZyc09","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wa6sc_fZVdvE","colab_type":"text"},"source":["### 3.  HDBScan en cada cluster para detectar anomalías."]},{"cell_type":"code","metadata":{"id":"SrLIGTF1W-3v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"executionInfo":{"status":"ok","timestamp":1600820937536,"user_tz":180,"elapsed":64139,"user":{"displayName":"sofia lujan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRjGY1pGqEbZ6NzzBty0QMgutVKtWpvUr5f7ch8Q=s64","userId":"04644358706352499859"}},"outputId":"056fe1bb-1da5-4064-bbea-66dc6fc5ea6a"},"source":["!pip install hdbscan"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting hdbscan\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/2f/2423d844072f007a74214c1adc46260e45f034bb1679ccadfbb8a601f647/hdbscan-0.8.26.tar.gz (4.7MB)\n","\u001b[K     |████████████████████████████████| 4.7MB 2.9MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.18.5)\n","Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.22.2.post1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.16.0)\n","Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.29.21)\n","Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.15.0)\n","Building wheels for collected packages: hdbscan\n","  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdbscan: filename=hdbscan-0.8.26-cp36-cp36m-linux_x86_64.whl size=2301797 sha256=bbe351f063b18970aa101d87c0c8002c8f9bde185b40820780678c5256d16963\n","  Stored in directory: /root/.cache/pip/wheels/82/38/41/372f034d8abd271ef7787a681e0a47fc05d472683a7eb088ed\n","Successfully built hdbscan\n","Installing collected packages: hdbscan\n","Successfully installed hdbscan-0.8.26\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7_z2rbkhViJ5","colab_type":"code","colab":{}},"source":["import hdbscan\n","clusterer = hdbscan.HDBSCAN(metric='manhattan')\n","clusterer.fit(df)\n","clusterer.labels_\n","clusterer.probabilities_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32U8DOFECwXO","colab_type":"text"},"source":["### III. Opcional - Tareas Adicionales"]},{"cell_type":"code","metadata":{"id":"Vq6E3j27CwCe","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}